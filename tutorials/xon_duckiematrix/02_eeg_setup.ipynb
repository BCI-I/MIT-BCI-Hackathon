{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Setup\n",
    "## Introduction\n",
    "This tutorial assumes that you have a working wireless EEG headset streaming raw EEG data over WiFi. To receive and visualize the raw EEG data, your device must support the [Lab Streaming Layer](https://labstreaminglayer.org/#/). Please check with the device manufacturer to see if the device supports LSL. If it does not, you may need to use a third-party application to convert the raw EEG data to LSL format.\n",
    "You will also need to ensure that both your EEG device and your device running this tutorial are connected to the same WiFi network to be able to receive the data.\n",
    "\n",
    "In this tutorial we will start with learning how to stream and visualize raw data, we will then move on to filtering and processing the data.\n",
    "\n",
    "## Streaming with LSL\n",
    "The Lab Streaming Layer (LSL) is a system for the unified collection of measurement time series in research experiments that handles time synchronization, time-stamping, and event markers. It is a set of open-source tools for the recording, streaming, and sharing of time series data, and is widely used in the field of neuroscience. LSL is a great tool for streaming EEG data, as it allows for easy synchronization of data from multiple devices and sensors. Before starting, we recomend that you read the [LSL documentation](https://labstreaminglayer.readthedocs.io/info/getting_started.html) to get a better understanding of how LSL works.\n",
    "\n",
    "Here, we will use the `pylsl` library to receive the raw EEG data. The pylsl library is a Python library that provides a simple interface for receiving data from LSL streams. It is a wrapper around the C++ LSL library, and provides a simple and easy-to-use interface for working with LSL streams in Python. \n",
    "\n",
    "Once your EEG device is streaming data over the WiFi network, you can use `pylsl` to identify the data stream corresponding to your EEG data and receive it. \n",
    "The following code looks for every `EEG` stream on the network and prints some useful information about it.  You can use this information to identify which stream is the correct one for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylsl import StreamInlet, resolve_stream, StreamInfo\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import lfilter, lfilter_zi, firwin\n",
    "from time import sleep\n",
    "from typing import Optional, Callable\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve EEG streams\n",
    "streams = resolve_stream()\n",
    "\n",
    "# Iterate through streams\n",
    "print(f\"Found {len(streams)} streams\")\n",
    "print(\"---------------\")\n",
    "\n",
    "for stream in streams:\n",
    "    print(\"Stream Name:\", stream.name())\n",
    "    print(\"Stream Type:\", stream.type())\n",
    "    print(\"Stream ID:\", stream.source_id())   # this should match your X.on Serial Number\n",
    "    print(\"Stream Unique Identifier:\", stream.uid())\n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function to allow us to find the stream we are interested in. This function will look for a stream with a specific name and type, and return the first stream that matches the criteria.\n",
    "Note that your function should also raise errors and provide messages to inform the user if the stream is not found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "def get_lsl_stream(target_stream_name:str, n_attempts:int=100,) -> StreamInfo:\n",
    "    \"\"\"Get LSL API for given EEG stream name.\n",
    "    \n",
    "    Args:\n",
    "        target_stream_name: String. Name of target stream.\n",
    "        n_attempts: Int. Number of attempts to look for the stream.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"looking for an EEG stream...\")\n",
    "    # Loop for a while to look for the EEG stream, because sometimes the stream\n",
    "    # is not found by resolve_stream() even when it exists\n",
    "    for _ in range(n_attempts):\n",
    "        streams = resolve_stream('type', 'EEG')\n",
    "        for stream in streams:\n",
    "            if stream.name() == target_stream_name:\n",
    "                return stream\n",
    "                break\n",
    "            \n",
    "\n",
    "    raise ValueError(f'Cannot find stream {target_stream_name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming and visualizing data \n",
    "\n",
    "stream: LSL data stream.\n",
    "feature_extractor: Callable mapping data -> features.\n",
    "window: Scalar. Window size in seconds for data caching and\n",
    "    plotting.\n",
    "buf: Int. Number of second for the data stream buffer.\n",
    "subsample_plot: Int. Stride for subsampling data when plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream: StreamInfo = get_lsl_stream(\"YOUR_STREAM_NAME\")\n",
    "window: int=5\n",
    "buf: int=1 \n",
    "subsample_plot: int=3 \n",
    "plot: bool=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# createa a StreamInlet to get data from the stream\n",
    "inlet = StreamInlet(stream, max_buflen=buf, max_chunklen=buf)\n",
    "\n",
    "# General metadata about inlet stream\n",
    "info = inlet.info()\n",
    "sfreq = info.nominal_srate()\n",
    "n_samples = int(sfreq * window)\n",
    "n_chan = info.channel_count()\n",
    "\n",
    "# Initialize variables for data and times\n",
    "times = np.arange(-window, 0, 1. / sfreq)\n",
    "data = np.zeros((n_samples, n_chan))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_data(inlet: StreamInlet, times: np.ndarray, data: np.ndarray, sfreq: int, window: int, n_samples: int, filter_fn:Optional[Callable]=None,) -> None:\n",
    "    samples, timestamps = inlet.pull_chunk(\n",
    "            timeout=0.01, max_samples=24)\n",
    "    while inlet.samples_available() > 50:\n",
    "        samples, timestamps = inlet.pull_chunk(\n",
    "            timeout=0.01, max_samples=24)\n",
    "    \n",
    "    if not (isinstance(timestamps, list) and len(timestamps) > 1):\n",
    "        sleep(0.01)\n",
    "        return \n",
    "    \n",
    "    # Dejitter and append times\n",
    "    num_new_samples = len(timestamps)\n",
    "    timestamps = np.float64(np.arange(num_new_samples)) / sfreq\n",
    "    timestamps += times[-1] + 1. / sfreq\n",
    "    times = np.concatenate([times, timestamps])\n",
    "    n_samples = int(sfreq * window)\n",
    "    times = times[-n_samples:]\n",
    "\n",
    "    # potentially filter function\n",
    "    if filter_fn is not None:\n",
    "        samples = filter_fn(samples)\n",
    "    \n",
    "    # Add new data\n",
    "    data = np.vstack([data, samples])\n",
    "    data = data[-n_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_raw = plt.subplots(figsize=(6, 8))\n",
    "times_plot = times[::subsample_plot]\n",
    "\n",
    "# Data lines\n",
    "lines_data = []\n",
    "for channel in range(n_chan):\n",
    "    line, = ax_raw.plot(\n",
    "        times_plot, np.zeros_like(times_plot) - channel, lw=1)\n",
    "    lines_data.append(line)\n",
    "lines_data = lines_data\n",
    "ax_raw.set_ylim(-n_chan - 0.5, 0.5)\n",
    "ax_raw.set_xlabel('Time (s)')\n",
    "ax_raw.xaxis.grid(False)\n",
    "ax_raw.set_yticks(np.arange(0, -n_chan, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_plot(\n",
    "    times: np.ndarray, data: np.ndarray, lines_data: list, ax_raw: plt.Axes, window: int, subsample_plot: int=3,\n",
    ") -> None:\n",
    "    # Update data plot\n",
    "    plot_data = np.copy(data[::subsample_plot])\n",
    "    plot_data -= np.nanmean(plot_data, axis=0, keepdims=True)\n",
    "    plot_data /= 3 * np.nanstd(plot_data, axis=0, keepdims=True)\n",
    "    for chan in range(n_chan):\n",
    "        lines_data[chan].set_xdata(\n",
    "            times[::subsample_plot] - times[-1])\n",
    "        lines_data[chan].set_ydata(plot_data[:, chan] - chan)\n",
    "    ax_raw.set_xlim(-window, 0)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a loop, pulling data and updating the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 1000\n",
    "UPDATE_PLOT_EVERY = int(0.2 / (12 / sfreq))\n",
    "\n",
    "update_idx = 0\n",
    "for _ in range(N_STEPS):\n",
    "    pull_data(inlet, times, data, sfreq, window, n_samples)\n",
    "\n",
    "    if update_idx % UPDATE_PLOT_EVERY == 0:\n",
    "        update_plot(times, data, lines_data, ax_raw, window, subsample_plot)\n",
    "    update_idx += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering data\n",
    "\n",
    "Filtering raw EEG data is crucial for extracting meaningful information and reducing noise artifacts, ensuring accurate interpretation and analysis of brain signals. Raw EEG signals often contain various sources of noise, including muscle activity, electrical interference, and environmental artifacts, which can obscure underlying neural activity. Filtering techniques help remove unwanted noise while preserving relevant neural information, enhancing the signal-to-noise ratio and improving the quality of EEG recordings. Commonly used types of filters include:\n",
    "\n",
    "    Bandpass Filters: Bandpass filters selectively attenuate frequencies outside of a specified range, allowing researchers to focus on the frequency bands of interest in EEG analysis. For example, alpha (8-12 Hz) and beta (12-30 Hz) bandpass filters are commonly used to isolate rhythmic brain activity associated with different cognitive states.\n",
    "\n",
    "    Notch Filters: Notch filters are used to suppress specific frequencies, typically powerline noise at 50 or 60 Hz and its harmonics, which can contaminate EEG recordings due to electrical interference from power sources. Notch filters help remove these unwanted artifacts, improving the signal quality.\n",
    "\n",
    "    High-pass Filters: High-pass filters attenuate low-frequency components in EEG signals, such as slow drifts and baseline fluctuations, while preserving higher-frequency neural activity. High-pass filtering helps remove baseline wander and DC offsets, ensuring a stable baseline for subsequent analysis.\n",
    "\n",
    "    Low-pass Filters: Low-pass filters attenuate high-frequency noise and artifacts, such as muscle activity and electrode movement, while preserving slow-wave components of EEG signals. Low-pass filtering helps smoothen the EEG signal and reduce high-frequency noise, improving signal clarity.\n",
    "\n",
    "By applying appropriate filtering techniques, researchers can enhance the interpretability and reliability of EEG data, enabling more accurate analysis and insights into brain function and behavior. Effective filtering is essential for unlocking the full potential of EEG-based research and applications in neuroscience, clinical diagnostics, and brain-computer interfaces.\n",
    "\n",
    "\n",
    "Here, we will filter the data with a finite impulse response filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables for filtering\n",
    "bf = firwin(\n",
    "    32,\n",
    "    np.array([1, 40]) / (sfreq / 2.),\n",
    "    width=0.05,\n",
    "    pass_zero=False,\n",
    ")\n",
    "af: list = [1.0]\n",
    "zi: np.ndarray = lfilter_zi(bf, af)\n",
    "filt_state: np.ndarray = np.tile(zi, (n_chan, 1)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_raw = plt.subplots(figsize=(6, 8))\n",
    "times_plot = times[::subsample_plot]\n",
    "\n",
    "# Data lines\n",
    "lines_data = []\n",
    "for channel in range(n_chan):\n",
    "    line, = ax_raw.plot(\n",
    "        times_plot, np.zeros_like(times_plot) - channel, lw=1)\n",
    "    lines_data.append(line)\n",
    "lines_data = lines_data\n",
    "ax_raw.set_ylim(-n_chan - 0.5, 0.5)\n",
    "ax_raw.set_xlabel('Time (s)')\n",
    "ax_raw.xaxis.grid(False)\n",
    "ax_raw.set_yticks(np.arange(0, -n_chan, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_samples(samples: np.ndarray, af:list, bf: np.ndarray, filt_state: np.ndarray) -> np.ndarray:\n",
    "    return lfilter(\n",
    "            bf, af, samples, axis=0, zi=filt_state\n",
    "    )\n",
    "    \n",
    "\n",
    "# define a lambda function for simplicity\n",
    "_filter_samples = lambda samples: filter_samples(samples, af, bf, filt_state)\n",
    "\n",
    "\n",
    "# now do the same as before, but with the filter function\n",
    "for _ in range(N_STEPS):\n",
    "    pull_data(inlet, times, data, sfreq, window, n_samples, filter_fn=_filter_samples)\n",
    "\n",
    "    if update_idx % UPDATE_PLOT_EVERY == 0:\n",
    "        update_plot(times, data, lines_data, ax_raw, window, subsample_plot)\n",
    "    update_idx += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with the filter parameters to see how that affects the data!\n",
    "\n",
    "## Features\n",
    "Beyond filtering, before passing the data to a machine learning model, we may want to extract features from the data.\n",
    "Feature extraction is the process of transforming raw data into a set of features that capture relevant information for a specific task or application. \n",
    "In this case, we will take the rolling standard deviation of each EEG channel (which roughly corresponds to the envelope of the EEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize some variables\n",
    "recent_stddevs = []\n",
    "baseline_stddevs = None\n",
    "n_features = 7  # will be specific to the EEG headset you're using\n",
    "history_chunks=100  #  Number of recent data chunks to use for computing the baseline stddev per channel.\n",
    " \n",
    "# define a function\n",
    "def extract_features(data: np.ndarray, recent_stddevs: list, baseline_stddevs: Optional[np.ndarray]=None, n_features: int=7, history_chunks: int=100) -> tuple:\n",
    "    \"\"\"Process batch of data of shape [timesteps_per_chunk, n_features].\"\"\"\n",
    "    \n",
    "    # Trim unused channels\n",
    "    data = data[:, :n_features]\n",
    "    \n",
    "    # Zero-mean the data\n",
    "    data -= np.nanmean(data, axis=0, keepdims=True)\n",
    "    \n",
    "    # Compute current stddevs\n",
    "    current_stddevs = np.nanstd(data, axis=0)\n",
    "\n",
    "    # Compute baseline (mean) stddev per channel\n",
    "    if baseline_stddevs is None:\n",
    "        recent_stddevs.append(current_stddevs)\n",
    "        if len(recent_stddevs) > history_chunks:\n",
    "            recent_stddevs.pop(0)\n",
    "        baseline_stddevs = np.mean(recent_stddevs, axis=0)\n",
    "    else:\n",
    "        baseline_stddevs = baseline_stddevs\n",
    "    \n",
    "    # Features are normalized stddevs\n",
    "    features = current_stddevs / baseline_stddevs\n",
    "\n",
    "    return features, baseline_stddevs, recent_stddevs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the loop as again, but we keep track of both the filtered data and the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.zeros((n_samples, n_chan))\n",
    "\n",
    "def update_features(\n",
    "    data: np.ndarray, features: np.ndarray, baseline_stddevs: np.ndarray, recent_stddevs: list, n_channels: int=7, history_chunks: int=100,\n",
    ") -> tuple:\n",
    "    new_features, baseline_stddevs, recent_stddevs = extract_features(\n",
    "        data, recent_stddevs, baseline_stddevs, n_channels, history_chunks\n",
    "    )\n",
    "    features = np.vstack([features, new_features])\n",
    "    features = features[-n_samples:]\n",
    "    return features, baseline_stddevs, recent_stddevs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new figure with an ax to plot the features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(6, 8))\n",
    "ax_raw, ax_feat = axes\n",
    "times_plot = times[::subsample_plot]\n",
    "\n",
    "# Data lines\n",
    "lines_data = []\n",
    "for channel in range(n_chan):\n",
    "    line, = ax_raw.plot(\n",
    "        times_plot, np.zeros_like(times_plot) - channel, lw=1)\n",
    "    lines_data.append(line)\n",
    "lines_data = lines_data\n",
    "ax_raw.set_ylim(-n_chan - 0.5, 0.5)\n",
    "ax_raw.set_xlabel('Time (s)')\n",
    "ax_raw.xaxis.grid(False)\n",
    "ax_raw.set_yticks(np.arange(0, -n_chan, -1))\n",
    "\n",
    "# Feature lines\n",
    "lines_feat = []\n",
    "for channel in range(n_features):\n",
    "    line, = ax_feat.plot(\n",
    "        times_plot, np.zeros_like(times_plot) - channel, lw=1)\n",
    "    lines_feat.append(line)\n",
    "lines_feat = lines_feat\n",
    "ax_feat.set_ylim(-n_features - 0.5, 0.5)\n",
    "ax_feat.set_xlabel('Time (s)')\n",
    "ax_feat.xaxis.grid(False)\n",
    "ax_feat.set_yticks(np.arange(0, -n_features, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the same as before, but with the filter function\n",
    "for _ in range(N_STEPS):\n",
    "    pull_data(inlet, times, data, sfreq, window, n_samples, filter_fn=_filter_samples)\n",
    "    features, baseline_stddevs, recent_stddevs = update_features(\n",
    "        data, features, baseline_stddevs, recent_stddevs, n_features, history_chunks\n",
    "    )\n",
    "\n",
    "    if update_idx % UPDATE_PLOT_EVERY == 0:\n",
    "        update_plot(times, data, lines_data, ax_raw, window, subsample_plot)\n",
    "        update_plot(times, features, lines_feat, ax_feat, window, subsample_plot)\n",
    "    update_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In the next tutorial we will design and implement a simple machine learning model and we will write some code to generate the data we need to train it.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
